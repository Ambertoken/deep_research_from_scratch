{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## `1_scoping.ipynb`\n",
    "\n",
    "### Try adding your own evaluation examples and / or building additional evaluators\n",
    "\n",
    "N / A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2_research_agent.ipynb\n",
    "\n",
    "### 1. Async Search Implementation for Parallelization\n",
    "\n",
    "One significant improvement is converting our search tool to use async operations for parallel execution. This dramatically reduces latency when performing multiple searches. Here's how to implement it based on the [reference implementation](https://github.com/langchain-ai/deep_research_from_scratch/blob/dbf54264b65003fc2dca250bac9d0b9b2ea3b03b/src/deep_research_from_scratch/utils.py):\n",
    "\n",
    "#### Current Synchronous Approach\n",
    "Our current implementation processes searches sequentially:\n",
    "\n",
    "```python\n",
    "def tavily_search_multiple(search_queries: List[str]) -> List[dict]:\n",
    "    search_docs = []\n",
    "    for query in search_queries:  # Sequential execution\n",
    "        result = tavily_client.search(query)\n",
    "        search_docs.append(result)\n",
    "    return search_docs\n",
    "```\n",
    "\n",
    "####  Async Implementation for Parallel Execution\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from langchain_core.tools import atool\n",
    "\n",
    "async def tavily_search_multiple_async(\n",
    "    search_queries: List[str], \n",
    "    max_results: int = 3,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = True\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Perform multiple searches concurrently using async operations.\n",
    "    \n",
    "    This approach can reduce total search time from N*search_time to \n",
    "    max(search_times) when searches are independent.\n",
    "    \"\"\"\n",
    "    tavily_client = TavilyClient()\n",
    "    \n",
    "    async def execute_single_search(query: str) -> dict:\n",
    "        \"\"\"Execute a single search operation asynchronously.\"\"\"\n",
    "        # Wrap the synchronous Tavily call in a thread executor\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return await loop.run_in_executor(\n",
    "            None,  # Use default thread pool\n",
    "            lambda: tavily_client.search(\n",
    "                query,\n",
    "                max_results=max_results,\n",
    "                include_raw_content=include_raw_content,\n",
    "                topic=topic\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Execute all searches concurrently\n",
    "    search_tasks = [execute_single_search(query) for query in search_queries]\n",
    "    search_results = await asyncio.gather(*search_tasks)\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "# Async tool definition\n",
    "@atool(description=\"Async web search utility with parallel execution\")\n",
    "async def tavily_search_async(\n",
    "    queries: List[str],\n",
    "    max_results: Annotated[int, InjectedToolArg] = 3,\n",
    "    topic: Annotated[Literal[\"general\", \"news\", \"finance\"], InjectedToolArg] = \"general\",\n",
    "    config: RunnableConfig = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetches results from Tavily search API with parallel execution.\n",
    "    \n",
    "    Performance improvement: For N queries, reduces time from N*T to ~T\n",
    "    where T is the time for a single search operation.\n",
    "    \"\"\"\n",
    "    # Execute searches concurrently\n",
    "    search_results = await tavily_search_multiple_async(\n",
    "        queries,\n",
    "        max_results=max_results,\n",
    "        topic=topic,\n",
    "        include_raw_content=True\n",
    "    )\n",
    "    \n",
    "    # Process results (same as synchronous version)\n",
    "    unique_results = deduplicate_search_results(search_results)\n",
    "    summarized_results = process_search_results(unique_results)\n",
    "    return format_search_output(summarized_results)\n",
    "```\n",
    "\n",
    "####  Agent Integration with Async Tools\n",
    "\n",
    "When using async tools, your agent nodes need to handle async execution:\n",
    "\n",
    "```python\n",
    "async def tool_node_async(state: ResearcherState):\n",
    "    \"\"\"Tool execution node that handles async tool calls.\"\"\"\n",
    "    tool_calls = state[\"researcher_messages\"][-1].tool_calls\n",
    "    \n",
    "    # Prepare async tool calls\n",
    "    async_tasks = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        if hasattr(tool, 'ainvoke'):\n",
    "            # Use async invocation if available\n",
    "            task = tool.ainvoke(tool_call[\"args\"])\n",
    "        else:\n",
    "            # Fallback to sync in thread executor\n",
    "            loop = asyncio.get_event_loop()\n",
    "            task = loop.run_in_executor(None, tool.invoke, tool_call[\"args\"])\n",
    "        async_tasks.append((tool_call, task))\n",
    "    \n",
    "    # Execute all tool calls concurrently\n",
    "    observations = []\n",
    "    tool_calls_ordered = []\n",
    "    \n",
    "    for tool_call, task in async_tasks:\n",
    "        observation = await task\n",
    "        observations.append(observation)\n",
    "        tool_calls_ordered.append(tool_call)\n",
    "    \n",
    "    # Create tool message outputs\n",
    "    tool_outputs = [\n",
    "        ToolMessage(\n",
    "            content=observation,\n",
    "            name=tool_call[\"name\"], \n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        ) for observation, tool_call in zip(observations, tool_calls_ordered)\n",
    "    ]\n",
    "    \n",
    "    return {\"researcher_messages\": tool_outputs}\n",
    "\n",
    "# Update agent with async nodes\n",
    "agent_builder = StateGraph(ResearcherState, output_schema=ResearcherOutputState)\n",
    "agent_builder.add_node(\"llm_call\", llm_call)  \n",
    "agent_builder.add_node(\"tool_node\", tool_node_async)  # Use async version\n",
    "agent_builder.add_node(\"compress_research\", compress_research)\n",
    "```\n",
    "\n",
    "####  Performance Benefits\n",
    "\n",
    "**Time Complexity Improvement:**\n",
    "- **Sequential**: O(n × search_time) where n = number of queries\n",
    "- **Parallel**: O(max(search_times)) ≈ O(search_time) for independent searches\n",
    "\n",
    "**Real-world Impact:**\n",
    "- 3 searches taking 2s each: 6s → ~2s (3x faster)\n",
    "- 5 searches taking 1.5s each: 7.5s → ~1.5s (5x faster)\n",
    "\n",
    "**Resource Considerations:**\n",
    "- Higher memory usage due to concurrent operations\n",
    "- API rate limiting may still apply\n",
    "- Network bandwidth shared across parallel requests\n",
    "\n",
    "####  Error Handling with Async\n",
    "\n",
    "```python\n",
    "async def robust_parallel_search(queries: List[str]) -> List[dict]:\n",
    "    \"\"\"Parallel search with proper error handling.\"\"\"\n",
    "    \n",
    "    async def safe_search(query: str) -> dict:\n",
    "        \"\"\"Execute search with error recovery.\"\"\"\n",
    "        try:\n",
    "            return await execute_single_search(query)\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed for '{query}': {e}\")\n",
    "            return {\"query\": query, \"results\": [], \"error\": str(e)}\n",
    "    \n",
    "    # Execute with error isolation\n",
    "    search_tasks = [safe_search(query) for query in queries]\n",
    "    results = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
    "    \n",
    "    # Filter successful results\n",
    "    valid_results = [r for r in results if not isinstance(r, Exception)]\n",
    "    return valid_results\n",
    "```\n",
    "\n",
    "####  When to Use Async vs Sync\n",
    "\n",
    "**Use Async When:**\n",
    "- Multiple independent search queries\n",
    "- I/O-bound operations (API calls, file operations)\n",
    "- Agent performs many tool calls concurrently\n",
    "- Time-sensitive research scenarios\n",
    "\n",
    "**Use Sync When:**\n",
    "- Single search queries\n",
    "- Sequential dependencies between searches\n",
    "- Simpler debugging and development\n",
    "- API has strict rate limiting\n",
    "\n",
    "This async approach significantly improves agent performance when conducting comprehensive research that requires multiple independent searches.\n",
    "\n",
    "### 2. Enhanced Prompt Engineering for Summarization\n",
    "\n",
    "Our current summarization is basic. We can improve it by focusing on research-specific needs:\n",
    "\n",
    "```python\n",
    "RESEARCH_FOCUSED_SUMMARIZATION_PROMPT = \"\"\"\n",
    "You are summarizing web content for research purposes. Extract the most valuable information for answering research questions.\n",
    "\n",
    "FOCUS ON:\n",
    "- Key facts, statistics, and quantitative data\n",
    "- Expert opinions and authoritative statements  \n",
    "- Recent developments and current trends\n",
    "- Comparative information and rankings\n",
    "- Methodological details and data sources\n",
    "\n",
    "EXTRACT:\n",
    "- 3-5 most important points as bullet points\n",
    "- Relevant direct quotes with context\n",
    "- Specific numbers, dates, and statistics\n",
    "- Source credibility indicators\n",
    "\n",
    "IGNORE:\n",
    "- Advertisements and promotional content\n",
    "- Navigation menus and website metadata\n",
    "- Unrelated sidebar content\n",
    "- Generic background information\n",
    "\n",
    "Webpage content: {webpage_content}\n",
    "Current date: {date}\n",
    "\n",
    "Provide a structured summary with clear sections for facts, quotes, and key insights.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 3. Intelligent Model Selection\n",
    "\n",
    "Different models excel at different tasks. Consider using specialized models:\n",
    "\n",
    "```python\n",
    "def get_model_for_task(task_type: str):\n",
    "    \"\"\"Select optimal model based on task requirements\"\"\"\n",
    "    if task_type == \"summarization\":\n",
    "        # Faster, cheaper model for content summarization\n",
    "        return init_chat_model(\"openai:gpt-4.1-mini\")\n",
    "    elif task_type == \"research_analysis\":\n",
    "        # More powerful model for complex analysis\n",
    "        return init_chat_model(\"openai:gpt-4.1\")\n",
    "    elif task_type == \"factual_extraction\":\n",
    "        # Model optimized for accuracy\n",
    "        return init_chat_model(\"anthropic:claude-3-sonnet\")\n",
    "    return init_chat_model(\"openai:gpt-4.1\")  # Default\n",
    "```\n",
    "\n",
    "### 4. Heuristic Search Result Filtering\n",
    "\n",
    "Implement quality filters to improve result relevance:\n",
    "\n",
    "```python\n",
    "def filter_search_results(results: List[dict], query_terms: List[str]) -> List[dict]:\n",
    "    \"\"\"Apply heuristics to improve result quality and relevance\"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for result in results:\n",
    "        # Content quality signals\n",
    "        content_length = len(result.get('content', ''))\n",
    "        if content_length < 100:  # Too short, likely not informative\n",
    "            continue\n",
    "        if content_length > 50000:  # Extremely long, may be spam\n",
    "            continue\n",
    "            \n",
    "        # Title quality indicators\n",
    "        title = result.get('title', '').lower()\n",
    "        if title.count('|') > 3:  # Likely spam or poorly formatted\n",
    "            continue\n",
    "        if any(spam_word in title for spam_word in ['buy now', 'click here', 'free trial']):\n",
    "            continue\n",
    "            \n",
    "        # Domain credibility (customize based on your domain)\n",
    "        url = result.get('url', '')\n",
    "        trusted_domains = ['.edu', '.gov', '.org', 'wikipedia.org', 'reuters.com', 'bbc.com']\n",
    "        is_trusted = any(domain in url for domain in trusted_domains)\n",
    "        \n",
    "        # Relevance scoring\n",
    "        relevance_score = calculate_relevance_score(result, query_terms)\n",
    "        \n",
    "        if relevance_score > 0.3 or is_trusted:  # Keep if relevant or from trusted source\n",
    "            result['relevance_score'] = relevance_score\n",
    "            result['is_trusted'] = is_trusted\n",
    "            filtered.append(result)\n",
    "    \n",
    "    # Sort by relevance and trust\n",
    "    return sorted(filtered, key=lambda x: (x.get('is_trusted', False), x.get('relevance_score', 0)), reverse=True)\n",
    "\n",
    "def calculate_relevance_score(result: dict, query_terms: List[str]) -> float:\n",
    "    \"\"\"Calculate relevance score based on term frequency and positioning\"\"\"\n",
    "    content = (result.get('content', '') + ' ' + result.get('title', '')).lower()\n",
    "    title = result.get('title', '').lower()\n",
    "    \n",
    "    score = 0.0\n",
    "    for term in query_terms:\n",
    "        term = term.lower()\n",
    "        # Higher weight for title matches\n",
    "        score += title.count(term) * 0.3\n",
    "        # Standard weight for content matches\n",
    "        score += content.count(term) * 0.1\n",
    "        \n",
    "    # Normalize by content length\n",
    "    return min(score / len(content) * 1000, 1.0)\n",
    "```\n",
    "\n",
    "### 5. Alternative Search APIs\n",
    "\n",
    "Diversify your search capabilities with multiple APIs:\n",
    "\n",
    "```python\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "@tool\n",
    "def duckduckgo_search(query: str, max_results: int = 5) -> str:\n",
    "    \"\"\"Privacy-focused search without API keys or tracking\"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    results = search.run(f\"{query} site:edu OR site:org OR site:gov\")\n",
    "    return results\n",
    "\n",
    "@tool  \n",
    "def multi_source_search(queries: List[str], max_results: int = 3) -> str:\n",
    "    \"\"\"Search across multiple search engines for comprehensive coverage\"\"\"\n",
    "    tavily_results = tavily_search(queries, max_results)\n",
    "    duckduckgo_results = \"\\n\\n\".join([duckduckgo_search(q, max_results) for q in queries])\n",
    "    \n",
    "    return f\"=== TAVILY RESULTS ===\\n{tavily_results}\\n\\n=== DUCKDUCKGO RESULTS ===\\n{duckduckgo_results}\"\n",
    "```\n",
    "\n",
    "### 5. Advanced Content Processing\n",
    "\n",
    "Implement more sophisticated content analysis:\n",
    "\n",
    "```python\n",
    "def extract_structured_information(content: str, content_type: str) -> dict:\n",
    "    \"\"\"Extract structured information based on content type\"\"\"\n",
    "    \n",
    "    if content_type == \"product_review\":\n",
    "        return extract_product_features(content)\n",
    "    elif content_type == \"research_paper\":\n",
    "        return extract_research_findings(content)\n",
    "    elif content_type == \"news_article\":\n",
    "        return extract_news_facts(content)\n",
    "    else:\n",
    "        return extract_general_information(content)\n",
    "\n",
    "def extract_product_features(content: str) -> dict:\n",
    "    \"\"\"Extract product-specific information\"\"\"\n",
    "    # Use regex or NER to extract prices, ratings, features\n",
    "    import re\n",
    "    \n",
    "    price_pattern = r'\\$\\d+\\.?\\d*'\n",
    "    rating_pattern = r'(\\d+\\.?\\d*)\\s*(?:out of|/)?\\s*5\\s*stars?'\n",
    "    \n",
    "    prices = re.findall(price_pattern, content)\n",
    "    ratings = re.findall(rating_pattern, content)\n",
    "    \n",
    "    return {\n",
    "        \"prices\": prices,\n",
    "        \"ratings\": ratings,\n",
    "        \"features\": extract_feature_list(content)\n",
    "    }\n",
    "```\n",
    "\n",
    "### 6. Evaluation Framework\n",
    "\n",
    "Set up comprehensive evaluation for your search improvements:\n",
    "\n",
    "```python\n",
    "def evaluate_search_quality(search_results: str, ground_truth: dict) -> dict:\n",
    "    \"\"\"Evaluate search result quality across multiple dimensions\"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # Information coverage\n",
    "    metrics['coverage'] = calculate_information_coverage(search_results, ground_truth['required_info'])\n",
    "    \n",
    "    # Source diversity\n",
    "    metrics['source_diversity'] = calculate_source_diversity(search_results)\n",
    "    \n",
    "    # Factual accuracy (if ground truth available)\n",
    "    if 'facts' in ground_truth:\n",
    "        metrics['accuracy'] = calculate_factual_accuracy(search_results, ground_truth['facts'])\n",
    "    \n",
    "    # Recency of information\n",
    "    metrics['recency'] = calculate_information_recency(search_results)\n",
    "    \n",
    "    return metrics\n",
    "```\n",
    "\n",
    "### Exercise: Implementation Challenge\n",
    "\n",
    "Try implementing these improvements incrementally:\n",
    "\n",
    "1. **Start with prompt engineering**: Enhance the summarization prompt to focus on research-specific information\n",
    "2. **Add filtering**: Implement basic heuristic filtering for search results\n",
    "3. **Experiment with models**: Try different models for summarization and compare performance\n",
    "4. **Create evaluations**: Build simple evaluation metrics to measure improvement\n",
    "\n",
    "### Performance Considerations\n",
    "\n",
    "When implementing these improvements, consider:\n",
    "- **Latency**: More processing means slower responses\n",
    "- **Cost**: Advanced models and multiple API calls increase costs  \n",
    "- **Quality vs Speed**: Find the right balance for your use case\n",
    "- **Robustness**: Handle API failures and edge cases gracefully\n",
    "\n",
    "The key is to start simple and gradually add sophistication based on your specific research needs and performance requirements."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
